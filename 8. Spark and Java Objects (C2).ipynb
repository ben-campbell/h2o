{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"display: inline;\" >8. Spark and Java Objects (C2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, H2O will have to be integrated with various products in the big data ecosystem. Here we demonstrate this in two ways: (1) Integrating H2O with Spark via 'Sparkling Water', and (2) Using a trained H2O 'POJO' model. In this second exercise we will also make use of Spark (although not via the Sparkling Water interface).\n",
    "\n",
    "**Training a model with Sparkling Water:**\n",
    "\n",
    "Spark is a distributed cluster computing framework for general computation. H2O is a specialized computing framework for machine learning. As such, it will often make sense to integrate the two â€” to perform some aspects of the process (e.g. data wrangling, transformations) in Spark, while training models in H2O. 'Sparkling Water' is the interface for doing so.\n",
    "\n",
    "Here we retrain the K-means model on the Iris dataset, using the following `IrisCluster` class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~~java\n",
    "import org.apache.spark.sql.SparkSession;\n",
    "import org.apache.spark.sql.Dataset;\n",
    "import org.apache.spark.sql.Row;\n",
    "import org.apache.spark.api.java.JavaSparkContext;\n",
    "\n",
    "import org.apache.spark.h2o.JavaH2OContext;\n",
    "import water.Job;\n",
    "import water.fvec.H2OFrame;\n",
    "import hex.kmeans.*;\n",
    "import hex.kmeans.KMeansModel.KMeansParameters;\n",
    "import hex.kmeans.KMeansModel.KMeansOutput;\n",
    "\n",
    "import java.util.Arrays;\n",
    "import java.io.File;\n",
    "import java.io.FileOutputStream;\n",
    "import hex.Model.JavaModelStreamWriter;\n",
    "\n",
    "public class IrisCluster {\n",
    "  public static void main(String[] args) throws Exception {\n",
    "    String inputFile = args[0];\n",
    "             \n",
    "    SparkSession spark = SparkSession.builder().appName(\"Java Spark SQL basic example\").config(\"spark.some.config.option\", \"some-value\").getOrCreate();\n",
    "    JavaSparkContext jsc = new JavaSparkContext(spark.sparkContext());\n",
    "    JavaH2OContext jhc = JavaH2OContext.getOrCreate(jsc);\n",
    "\n",
    "    Dataset<Row> irisDF = spark.read().format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\", true).load(inputFile);\n",
    "    irisDF.show();\n",
    "\n",
    "    H2OFrame iris_hex = jhc.asH2OFrame(irisDF, \"iris_hex\");\n",
    "\n",
    "    double[] means = iris_hex.means();\n",
    "    System.out.println(iris_hex.toString());\n",
    "\n",
    "    KMeansParameters kmParams = new KMeansParameters();\n",
    "    kmParams._k = 3;\n",
    "    kmParams._train = iris_hex._key;\n",
    "\n",
    "    KMeans km = new KMeans(kmParams);\n",
    "    Job j = km.trainModel();\n",
    "    KMeansModel kmModel = km.get();\n",
    "\n",
    "    File destFile = new File(kmModel._key.toString() + \".java\");\n",
    "    FileOutputStream fos = new FileOutputStream(destFile);\n",
    "    JavaModelStreamWriter writer = kmModel.new JavaModelStreamWriter(false);\n",
    "    writer.writeTo(fos);\n",
    "    fos.close();\n",
    "  }\n",
    "}\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code was compiled in maven to create a shaded jar with the following dependencies:\n",
    "    \n",
    "~~~~xml\n",
    "  <dependencies>\n",
    "    <dependency> <!-- Spark dependency -->\n",
    "      <groupId>org.apache.spark</groupId>\n",
    "      <artifactId>spark-core_2.10</artifactId>\n",
    "      <version>1.1.0</version>\n",
    "      <scope>provided</scope>\n",
    "    </dependency>\n",
    "    <dependency> <!-- Spark dependency -->\n",
    "      <groupId>org.apache.spark</groupId>\n",
    "      <artifactId>spark-sql_2.11</artifactId>\n",
    "      <version>2.2.0</version>\n",
    "      <scope>provided</scope>\n",
    "    </dependency>\n",
    "    <dependency>\n",
    "      <groupId>ai.h2o</groupId>\n",
    "      <artifactId>sparkling-water-core_2.11</artifactId>\n",
    "      <version>2.2.1</version>\n",
    "    </dependency>\n",
    "  </dependencies>\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code was run in Spark using:\n",
    "    \n",
    "`$ spark-submit --class IrisCluster sparkh2oexample.jar iris.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this code is to produce a POJO, output to `KMeans_model_<modelnumber>_1.java`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Productionizing the POJO:** The outputted java object can then be referenced from any other Java/Scala program. Here we create a simple Spark program that makes use of the model to cluster the iris data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~~java\n",
    "import java.util.Arrays;\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "import java.lang.Double;\n",
    "import org.apache.commons.lang.StringUtils;\n",
    "import org.apache.spark.sql.SparkSession;\n",
    "import org.apache.spark.sql.Dataset;\n",
    "import org.apache.spark.sql.Row;\n",
    "import org.apache.spark.sql.types.*;\n",
    "import org.apache.spark.api.java.JavaRDD;\n",
    "import org.apache.spark.api.java.JavaPairRDD;\n",
    "import org.apache.spark.api.java.JavaSparkContext;\n",
    "import java.io.*;\n",
    "import hex.genmodel.easy.RowData;\n",
    "import hex.genmodel.easy.EasyPredictModelWrapper;\n",
    "import hex.genmodel.easy.prediction.*;\n",
    "\n",
    "public class IrisPredict {\n",
    "  private static String modelClassName = \"KMeans_model_1508336904807_1\";\n",
    "\n",
    "  public static void main(String[] args) throws Exception {\n",
    "  \n",
    "    // Set up H2O model\n",
    "\n",
    "    hex.genmodel.GenModel rawModel;\n",
    "    rawModel = (hex.genmodel.GenModel) Class.forName(modelClassName).newInstance();\n",
    "    EasyPredictModelWrapper model = new EasyPredictModelWrapper(rawModel);\n",
    "\n",
    "    // Get data into spark\n",
    "\n",
    "    String inputFile = \"iris.csv\";\n",
    "\n",
    "    SparkSession spark = SparkSession.builder().appName(\"H2O-example\").getOrCreate();\n",
    "    JavaSparkContext jsc = new JavaSparkContext(spark.sparkContext());\n",
    "\n",
    "    Dataset<Row> irisDF = spark.read().format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\", true).load(inputFile);\n",
    "\n",
    "    List<String> irisFields = Arrays.asList(\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\");\n",
    "\n",
    "    // Apply clustering model\n",
    "\n",
    "    irisDF.foreach( row -> {\n",
    "       List<String> listData = new ArrayList<>();\n",
    "       RowData rowData = new RowData();\n",
    "       for (String field: irisFields) {\n",
    "          listData.add(Double.toString(row.getAs(field)));\n",
    "          rowData.put(field, row.getAs(field));\n",
    "       }\n",
    "       ClusteringModelPrediction p = model.predictClustering(rowData);\n",
    "       listData.add(Integer.toString(p.cluster));\n",
    "       System.out.println(listData.toString());\n",
    "    });\n",
    "  }\n",
    "}\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program can be run from the attached JAR as follows:\n",
    "\n",
    "`$ spark-submit --class IrisPredict target/sparkh2oexample.jar iris.csv`\n",
    "\n",
    "The output consists of the iris data points, clustered to 0-2:\n",
    "    \n",
    "```\n",
    "[5.1, 3.5, 1.4, 0.2, 0]\n",
    "[4.9, 3.0, 1.4, 0.2, 0]\n",
    "[4.7, 3.2, 1.3, 0.2, 0]\n",
    "[4.6, 3.1, 1.5, 0.2, 0]\n",
    "[5.0, 3.6, 1.4, 0.2, 0]\n",
    "[5.4, 3.9, 1.7, 0.4, 0]\n",
    "[4.6, 3.4, 1.4, 0.3, 0]\n",
    "[5.0, 3.4, 1.5, 0.2, 0]\n",
    "[4.4, 2.9, 1.4, 0.2, 0]\n",
    "[4.9, 3.1, 1.5, 0.1, 0]\n",
    "[5.4, 3.7, 1.5, 0.2, 0]\n",
    "[4.8, 3.4, 1.6, 0.2, 0]\n",
    "[4.8, 3.0, 1.4, 0.1, 0]\n",
    "[4.3, 3.0, 1.1, 0.1, 0]\n",
    "[5.8, 4.0, 1.2, 0.2, 0]\n",
    "[5.7, 4.4, 1.5, 0.4, 0]\n",
    "[5.4, 3.9, 1.3, 0.4, 0]\n",
    "[5.1, 3.5, 1.4, 0.3, 0]\n",
    "[5.7, 3.8, 1.7, 0.3, 0]\n",
    "[5.1, 3.8, 1.5, 0.3, 0]\n",
    "[5.4, 3.4, 1.7, 0.2, 0]\n",
    "[5.1, 3.7, 1.5, 0.4, 0]\n",
    "[4.6, 3.6, 1.0, 0.2, 0]\n",
    "[5.1, 3.3, 1.7, 0.5, 0]\n",
    "[4.8, 3.4, 1.9, 0.2, 0]\n",
    "[5.0, 3.0, 1.6, 0.2, 0]\n",
    "[5.0, 3.4, 1.6, 0.4, 0]\n",
    "[5.2, 3.5, 1.5, 0.2, 0]\n",
    "[5.2, 3.4, 1.4, 0.2, 0]\n",
    "[4.7, 3.2, 1.6, 0.2, 0]\n",
    "[4.8, 3.1, 1.6, 0.2, 0]\n",
    "[5.4, 3.4, 1.5, 0.4, 0]\n",
    "[5.2, 4.1, 1.5, 0.1, 0]\n",
    "[5.5, 4.2, 1.4, 0.2, 0]\n",
    "[4.9, 3.1, 1.5, 0.1, 0]\n",
    "[5.0, 3.2, 1.2, 0.2, 0]\n",
    "[5.5, 3.5, 1.3, 0.2, 0]\n",
    "[4.9, 3.1, 1.5, 0.1, 0]\n",
    "[4.4, 3.0, 1.3, 0.2, 0]\n",
    "[5.1, 3.4, 1.5, 0.2, 0]\n",
    "[5.0, 3.5, 1.3, 0.3, 0]\n",
    "[4.5, 2.3, 1.3, 0.3, 0]\n",
    "[4.4, 3.2, 1.3, 0.2, 0]\n",
    "[5.0, 3.5, 1.6, 0.6, 0]\n",
    "[5.1, 3.8, 1.9, 0.4, 0]\n",
    "[4.8, 3.0, 1.4, 0.3, 0]\n",
    "[5.1, 3.8, 1.6, 0.2, 0]\n",
    "[4.6, 3.2, 1.4, 0.2, 0]\n",
    "[5.3, 3.7, 1.5, 0.2, 0]\n",
    "[5.0, 3.3, 1.4, 0.2, 0]\n",
    "[7.0, 3.2, 4.7, 1.4, 2]\n",
    "[6.4, 3.2, 4.5, 1.5, 2]\n",
    "[6.9, 3.1, 4.9, 1.5, 2]\n",
    "[5.5, 2.3, 4.0, 1.3, 1]\n",
    "[6.5, 2.8, 4.6, 1.5, 1]\n",
    "[5.7, 2.8, 4.5, 1.3, 1]\n",
    "[6.3, 3.3, 4.7, 1.6, 2]\n",
    "[4.9, 2.4, 3.3, 1.0, 1]\n",
    "[6.6, 2.9, 4.6, 1.3, 1]\n",
    "[5.2, 2.7, 3.9, 1.4, 1]\n",
    "[5.0, 2.0, 3.5, 1.0, 1]\n",
    "[5.9, 3.0, 4.2, 1.5, 1]\n",
    "[6.0, 2.2, 4.0, 1.0, 1]\n",
    "[6.1, 2.9, 4.7, 1.4, 1]\n",
    "[5.6, 2.9, 3.6, 1.3, 1]\n",
    "[6.7, 3.1, 4.4, 1.4, 2]\n",
    "[5.6, 3.0, 4.5, 1.5, 1]\n",
    "[5.8, 2.7, 4.1, 1.0, 1]\n",
    "[6.2, 2.2, 4.5, 1.5, 1]\n",
    "[5.6, 2.5, 3.9, 1.1, 1]\n",
    "[5.9, 3.2, 4.8, 1.8, 2]\n",
    "[6.1, 2.8, 4.0, 1.3, 1]\n",
    "[6.3, 2.5, 4.9, 1.5, 1]\n",
    "[6.1, 2.8, 4.7, 1.2, 1]\n",
    "[6.4, 2.9, 4.3, 1.3, 1]\n",
    "[6.6, 3.0, 4.4, 1.4, 2]\n",
    "[6.8, 2.8, 4.8, 1.4, 2]\n",
    "[6.7, 3.0, 5.0, 1.7, 2]\n",
    "[6.0, 2.9, 4.5, 1.5, 1]\n",
    "[5.7, 2.6, 3.5, 1.0, 1]\n",
    "[5.5, 2.4, 3.8, 1.1, 1]\n",
    "[5.5, 2.4, 3.7, 1.0, 1]\n",
    "[5.8, 2.7, 3.9, 1.2, 1]\n",
    "[6.0, 2.7, 5.1, 1.6, 1]\n",
    "[5.4, 3.0, 4.5, 1.5, 1]\n",
    "[6.0, 3.4, 4.5, 1.6, 2]\n",
    "[6.7, 3.1, 4.7, 1.5, 2]\n",
    "[6.3, 2.3, 4.4, 1.3, 1]\n",
    "[5.6, 3.0, 4.1, 1.3, 1]\n",
    "[5.5, 2.5, 4.0, 1.3, 1]\n",
    "[5.5, 2.6, 4.4, 1.2, 1]\n",
    "[6.1, 3.0, 4.6, 1.4, 1]\n",
    "[5.8, 2.6, 4.0, 1.2, 1]\n",
    "[5.0, 2.3, 3.3, 1.0, 1]\n",
    "[5.6, 2.7, 4.2, 1.3, 1]\n",
    "[5.7, 3.0, 4.2, 1.2, 1]\n",
    "[5.7, 2.9, 4.2, 1.3, 1]\n",
    "[6.2, 2.9, 4.3, 1.3, 1]\n",
    "[5.1, 2.5, 3.0, 1.1, 1]\n",
    "[5.7, 2.8, 4.1, 1.3, 1]\n",
    "[6.3, 3.3, 6.0, 2.5, 2]\n",
    "[5.8, 2.7, 5.1, 1.9, 1]\n",
    "[7.1, 3.0, 5.9, 2.1, 2]\n",
    "[6.3, 2.9, 5.6, 1.8, 2]\n",
    "[6.5, 3.0, 5.8, 2.2, 2]\n",
    "[7.6, 3.0, 6.6, 2.1, 2]\n",
    "[4.9, 2.5, 4.5, 1.7, 1]\n",
    "[7.3, 2.9, 6.3, 1.8, 2]\n",
    "[6.7, 2.5, 5.8, 1.8, 2]\n",
    "[7.2, 3.6, 6.1, 2.5, 2]\n",
    "[6.5, 3.2, 5.1, 2.0, 2]\n",
    "[6.4, 2.7, 5.3, 1.9, 2]\n",
    "[6.8, 3.0, 5.5, 2.1, 2]\n",
    "[5.7, 2.5, 5.0, 2.0, 1]\n",
    "[5.8, 2.8, 5.1, 2.4, 1]\n",
    "[6.4, 3.2, 5.3, 2.3, 2]\n",
    "[6.5, 3.0, 5.5, 1.8, 2]\n",
    "[7.7, 3.8, 6.7, 2.2, 2]\n",
    "[7.7, 2.6, 6.9, 2.3, 2]\n",
    "[6.0, 2.2, 5.0, 1.5, 1]\n",
    "[6.9, 3.2, 5.7, 2.3, 2]\n",
    "[5.6, 2.8, 4.9, 2.0, 1]\n",
    "[7.7, 2.8, 6.7, 2.0, 2]\n",
    "[6.3, 2.7, 4.9, 1.8, 1]\n",
    "[6.7, 3.3, 5.7, 2.1, 2]\n",
    "[7.2, 3.2, 6.0, 1.8, 2]\n",
    "[6.2, 2.8, 4.8, 1.8, 1]\n",
    "[6.1, 3.0, 4.9, 1.8, 2]\n",
    "[6.4, 2.8, 5.6, 2.1, 2]\n",
    "[7.2, 3.0, 5.8, 1.6, 2]\n",
    "[7.4, 2.8, 6.1, 1.9, 2]\n",
    "[7.9, 3.8, 6.4, 2.0, 2]\n",
    "[6.4, 2.8, 5.6, 2.2, 2]\n",
    "[6.3, 2.8, 5.1, 1.5, 1]\n",
    "[6.1, 2.6, 5.6, 1.4, 1]\n",
    "[7.7, 3.0, 6.1, 2.3, 2]\n",
    "[6.3, 3.4, 5.6, 2.4, 2]\n",
    "[6.4, 3.1, 5.5, 1.8, 2]\n",
    "[6.0, 3.0, 4.8, 1.8, 1]\n",
    "[6.9, 3.1, 5.4, 2.1, 2]\n",
    "[6.7, 3.1, 5.6, 2.4, 2]\n",
    "[6.9, 3.1, 5.1, 2.3, 2]\n",
    "[5.8, 2.7, 5.1, 1.9, 1]\n",
    "[6.8, 3.2, 5.9, 2.3, 2]\n",
    "[6.7, 3.3, 5.7, 2.5, 2]\n",
    "[6.7, 3.0, 5.2, 2.3, 2]\n",
    "[6.3, 2.5, 5.0, 1.9, 1]\n",
    "[6.5, 3.0, 5.2, 2.0, 2]\n",
    "[6.2, 3.4, 5.4, 2.3, 2]\n",
    "[5.9, 3.0, 5.1, 1.8, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
